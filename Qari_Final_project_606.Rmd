---
title: "Final Project Data 606.Rmd"
author: "Mubashira Qari"
date: "April 30, 2022"
output: html_document
---

### Overview: 

Pymaceuticals Inc., a fictional burgeoning pharmaceutical company based out of San Diego, CA, specializes in drug-based, anti-cancer pharmaceuticals. They have provided the data to test the efficacy of potential drug treatments for squamous cell carcinoma. In this study, 249 mice identified with Squamous cell carcinoma (SCC) tumor growth, kind of skin cancer, were treated through a variety of drug regimens. Over the course of 45 days, tumor development was observed and measured. The objective is to analyze the data to show how four treatments (Capomulin, Infubinol, Ketapril, and Placebo) compare.


### Research question:

Question 1: Is Capomulin more or less effective in reducing the tumor size than Infubinol, or Ketapril drugs categories? 

Question 2: Is there a correlation between the age, weight and the tumor size growth for each drug category?


### Hypothesis Test

### Null Hypothesis: There is no difference between the mean percent change in tumor volume for the four drug categories.

### Alternate Hypothesis: There is a difference between the mean percent change in tumor volume for the four drug categories.

Approach for answering the research question will be: 

1- Calculate the mean percent change in tumor volume for the four drug categories.

2- Perform the Hypothesis test to find out whether the difference exists between the mean tumor size for all four drug categories.

3- Perform linear regression to study the correlation between various variables by calculating the correlation coefficient.

4- Finally analyze the results to find out if Capomulin more or less effective in reducing the tumor size of sample mice than Infubinol, or Ketapril drugs categories.


### Cases:

### What are the cases? How many different drug treatments are there? How many total samples size as well as the sample size by drug treatments are there?

Answer: The metadata_df contain 249 unique mouse id and so are the number of cases that treated with variety of drug regimen. The results_df dataset holds the tumor growth measurements observed for each Mouse ID and carries 1,893 rows results. There are 10 different drug treatments. The total sample size of mice for four treatments (Capomulin, Infubinol, Ketapril, and Placebo) is 100 and the sample size of mice by drug treatments is 25 each.


### Data collection:

### Describe the method of data collection.

Answer: Data is collected by the fictitious pharmaceutical company who was testing the efficacy of potential drug treatments for squamous cell carcinoma.
I import the data into Rmd file from GitHub.


### Type of study:

### What type of study is this (observational/experiment)?

Answer: This is an experimental study. A group of 249 mice were monitored after administration of a variety of drug regimens over a 45-day treatment period. The impact of Capomulin on tumor growth, metastasis and survival rates were monitored, along with Infubinol, Ketapril, and Placebo.


### Data Source:

### If you collected the data, state self-collected. If not, provide a citation/link.

Answer: The citation and data collection links are as follows. 

In my search for the experimental datasets, I found the mouse metadata and the Study results on the GitHub link provided below:

https://raw.githubusercontent.com/rfpoulos/pymaceuticals/master/data/Mouse_metadata.csv

https://raw.githubusercontent.com/rfpoulos/pymaceuticals/master/data/Study_results.csv

Upon further research in finding the original source of the dataset, I found that these datasets are provided by Pymaceuticals Inc., a fictional burgeoning pharmaceutical company based out of San Diego, CA, specializes in drug-based, anti-cancer pharmaceuticals. Below is the link for the original source of the datasets.


https://c-l-nguyen.github.io/web-design-challenge/index.html



### Response

### What is the response variable, and what type is it (numerical/categorical)?

Answer: The response variable is the size of tumor, "Tumor.Volume.mm3." and it holds a numerical data.

### Explanatory

What is the explanatory variable, and what type is it (numerical/categorical)?

Answer: The explanatory variable is the "Drug.Regimen" and it holds a categorical data and "Timepoint" which holds numerical data. The 'Timepoint' unit is 'days'.

### Units of Variables:

Weight(g)
Age_months(months)
Timepoint(days) - numerical explanatory variable
Drug.Regimen - categorical explanatory variable
Tumor.Volume(mm3) - response variable
Metastatic.Sites(satges of the spread of tumor)

### The initial Tumor Volume for starting point zero is 45 mm3 for all mice.
### Over the course of 45 days, tumor development was observed and measured.

### Relevant summary statistics: (Tables and Charts)

Provide summary statistics relevant to your research question. For example, if you’re comparing means across groups provide means, SDs, sample sizes of each group. This step requires the use of R; hence a code chunk is provided below. Insert more code chunks as needed.


### Libraries Imported

```{r}
library(tidyverse)
library(dplyr)
library(plotly)
library(tidyr)
library(stringr)
library(psych)
library(ggplot2)
```

### Data Preparation and Exploratory Data Analysis:

#### load dataset1

```{r }
metadata_df <- read.delim("https://raw.githubusercontent.com/rfpoulos/pymaceuticals/master/data/Mouse_metadata.csv", header=T, sep=",")
head(metadata_df)
```

### Grouping by Drug.Regimen

```{r}
df <- metadata_df %>%
  group_by(Drug.Regimen) 

head(df)
```

### Load dataset2

```{r}
results_df <- read.delim("https://raw.githubusercontent.com/rfpoulos/pymaceuticals/master/data/Study_results.csv", header=T, sep=",")
head(results_df)
```


```{r}
summary(metadata_df)
```

### Summary Statistic

```{r}
summary(results_df)
```

### Sample Sizes for metadata_df

```{r}
nrow(metadata_df)
```

### Sample Sizes for results_df

```{r}
nrow(results_df)
```

### How many drug treatments are there?

```{r}

drug_count <- unique(metadata_df$Drug.Regimen)

drug_count
```

```{r}

length(drug_count)
```

### Sample sizes of mouse_id by drug treatment

```{r}
capomulin_df <- filter(metadata_df, Drug.Regimen=="Capomulin")

head(capomulin_df)
```

```{r}
nrow(capomulin_df)
```

```{r}
infubinol_df <- filter(metadata_df, Drug.Regimen=="Infubinol")

nrow(infubinol_df)
```

```{r}
ketapril_df <- filter(metadata_df, Drug.Regimen=="Ketapril")

nrow(ketapril_df)
```

```{r}
placebo_df <- filter(metadata_df, Drug.Regimen=="Placebo")

nrow(placebo_df)
```

### Performing full outer join, for metadata and result dataframe, so that no data is lost

```{r}
merge_df <- merge(x = metadata_df, y = results_df, all = TRUE)

head(merge_df)
```

```{r}
glimpse(merge_df)
```

### Dropping the NA rows

```{r}
merge_df <- merge_df %>% drop_na()

head(merge_df)
```


### Rename colnames of some columns
### Assigning new names to the columns of the merged data frame


```{r}
colnames(merge_df)[1] <- c("Mouse_Id")
colnames(merge_df)[2] <- c("Drug_Regimen")
colnames(merge_df)[5] <- c("Weight_g")
colnames(merge_df)[7] <- c("Tumor_Volume_mm3")
colnames(merge_df)[8] <- c("Metastatic_Sites")

head(merge_df)
```

```{r}
merge_df %>% group_by(Mouse_Id, Timepoint)

head(merge_df)
```


### Remove duplicate rows across entire data frame

```{r}

merge_df <- merge_df[!duplicated(merge_df), ]

head(merge_df)
```

### filter by Capomulin, Infubinol, Ketapril, and Placebo

```{r}

capomulin_df <- filter(merge_df, Drug_Regimen == "Capomulin")
infubinol_df <- filter(merge_df, Drug_Regimen == "Infubinol")
ketapril_df <- filter(merge_df, Drug_Regimen == "Ketapril")
placebo_df <- filter(merge_df, Drug_Regimen == "Placebo")


head(capomulin_df)
```

### The initial Tumor Volume for starting point zero is 45 mm3 for all mice
### capomulin_df

```{r}
# Filtering the max timepoint values

capo_df <- select(capomulin_df, Mouse_Id, Drug_Regimen, Timepoint, Tumor_Volume_mm3, Age_months, Weight_g) %>%
   group_by(Mouse_Id) %>%
  filter(Timepoint == max(Timepoint, na.rm=TRUE))


head(capo_df)
```



```{r}
# Calculating the percent change in Tumor volume
capo_df <- capo_df %>% 
  mutate(percent_change_Tumor_Volume = ((Tumor_Volume_mm3-45)/45))
head(capo_df)
```

### The initial Tumor Volume for starting point zero is 45 mm3 for all mice
### Infubinol_df

```{r}
# Filtering the max timepoint values
infu_df <- select(infubinol_df, Mouse_Id, Drug_Regimen, Timepoint, Tumor_Volume_mm3, Age_months, Weight_g) %>%
   group_by(Mouse_Id) %>%
  filter(Timepoint == max(Timepoint, na.rm=TRUE))

# Calculating the percent change in Tumor volume
infu_df <- infu_df %>% 
  mutate(percent_change_Tumor_Volume = ((Tumor_Volume_mm3-45)/45))

head(infu_df)
```

### The initial Tumor Volume for starting point zero is 45 mm3 for all mice
### Ketapril_df

```{r}
# Filtering the max timepoint values
keta_df <- select(ketapril_df, Mouse_Id, Drug_Regimen, Timepoint, Tumor_Volume_mm3, Age_months, Weight_g) %>%
   group_by(Mouse_Id) %>%
  filter(Timepoint == max(Timepoint, na.rm=TRUE))

# Calculating the percent change in Tumor volume
keta_df <- keta_df %>% 
  mutate(percent_change_Tumor_Volume = ((Tumor_Volume_mm3-45)/45))

head(keta_df)
```

### The initial Tumor Volume for starting point zero is 45 mm3 for all mice
### Placebo_df

```{r}
plac_df <- select(placebo_df, Mouse_Id, Drug_Regimen, Timepoint, Tumor_Volume_mm3, Age_months, Weight_g) %>%
   group_by(Mouse_Id) %>%
  filter(Timepoint == max(Timepoint, na.rm=TRUE))

# Calculating the percent change in Tumor volume
plac_df <- plac_df %>% 
  mutate(percent_change_Tumor_Volume = ((Tumor_Volume_mm3-45)/45))

head(plac_df)
```

### Merging the grouped dataframes into new_df

```{r}

# put all data frames into list
df_list <- list(capo_df, infu_df, keta_df, plac_df)      

#merge all data frames together
new_df <- Reduce(function(x, y) merge(x, y, all=TRUE), df_list)  
head(new_df)
```

```{r}
#new_df$percent_change_Tumor_Volume = round(new_df$percent_change_Tumor_Volume, digit=2)
head(new_df)
```


### Comparing the percent change in tumor volumn size for each drug category

```{r}
test_df <- select(new_df, Drug_Regimen, percent_change_Tumor_Volume) %>%
  group_by(Drug_Regimen) %>%
 summarise(percent_change_Tumor_Volume = mean(percent_change_Tumor_Volume, na.rm=TRUE))

head(test_df)
```




```{r}
# plot mean salaries
ggplot(test_df, 
       aes(x = percent_change_Tumor_Volume, 
           y = Drug_Regimen, 
           fill=Drug_Regimen)) +
  geom_bar(stat = "identity")
```


### Summary statistics

Compute some summary statistics (count, mean and sd) of the variable weight organized by groups:

```{r}

# Summarize
new_df %>%
group_by(Drug_Regimen) %>%
  summarise(
    n = n(),
    max = max(percent_change_Tumor_Volume),
    min = min(percent_change_Tumor_Volume),
    mean = mean(percent_change_Tumor_Volume),
    median = median(percent_change_Tumor_Volume),
    sd = sd(percent_change_Tumor_Volume),
    quan_25th = quantile(percent_change_Tumor_Volume, 0.25),
    quan_75th = quantile(percent_change_Tumor_Volume, 0.75)
  )
```
### Visualization

```{r}
library(tidyverse)
library(rstatix)
library(ggpubr)
# Color by groups
ggsummarystats(
  new_df, x = "Drug_Regimen", y = "percent_change_Tumor_Volume", 
  ggfunc = ggboxplot, add = "jitter",
  color = "Drug_Regimen", palette = "npg"
  )
```


Create a box plot of percent_change_Tumor_Volume by Drug_Regimen:

```{r}
boxplot(new_df$percent_change_Tumor_Volume~new_df$Drug_Regimen, 
        main="Boxplot comparing percent_change_Tumor_Volume", 
         xlab = "Drug_Regimen", ylab = "percent_change_Tumor_Volume",
        col= rainbow(4))

```

### Analysis for the box plots: 

The drug categories represented on the x_axis and percent change in tumor size on the y_axis.

Infubinol drug category has one datapoint indicating the outlier. 

Infubinol and Ketapril drug category shows that the median and mean are closely alligned, which shows data is normally distributed, and we can ignore the outlier in Infubinol drug category.

Ketapril drug category has more variance of data points than the Infubinol drug category.

However, the mean < median in the Capomulin drug category, making it left skewed. Also, the percent change is tumor size is below zero, showing that the Capomulin drug is effective in reducing the size of tumor.

Since Capomulin drug category appears to be different than Infubinol and Ketapril drug category, which is an indication that we will find the difference between means of Capomulin drug and the other two categories.

#=============================================================================================================================

### To compare the means of three or more samples, One Way Variance (ANOVA) is the most appropriate test to use.


### Assumptions
The ANOVA test makes the following assumptions about the data:

Independence of the observations. Each subject should belong to only one group. There is no relationship between the observations in each group. Having repeated measures for the same participants is not allowed.
No significant outliers in any cell of the design
Normality. the data for each design cell should be approximately normally distributed.
Homogeneity of variances. The variance of the outcome variable should be equal in every cell of the design.


### Check assumptions
### Outliers

```{r}
new_df %>% 
  group_by(Drug_Regimen) %>%
  identify_outliers(percent_change_Tumor_Volume)
```
In this situation there is one outliers, this can be due to data entry errors, measurement errors or unusual values and the mean is not effected.

### Normality assumption

Check normality assumption by analyzing the model residuals. 
QQ plot and Shapiro-Wilk test of normality are used.

### QQ plot draws the correlation between a given data and the normal distribution.

```{r}
# Build the linear model
model  <- lm(percent_change_Tumor_Volume ~ Drug_Regimen, data = new_df)
# Create a QQ plot of residuals
ggqqplot(residuals(model),col="blue")
```

```{r}
# Compute Shapiro-Wilk test of normality
shapiro_test(residuals(model))
```
### Conclusion:

In the QQ plot, as all the points fall approximately along the reference line, we can assume normality. This conclusion is supported by the Shapiro-Wilk test. The p-value is not significant (p = 0.6), so we can assume normality.

### Check normality assumption by groups

Computing Shapiro-Wilk test for each group level. If the data is normally distributed, the p-value should be greater than 0.05.
```{r}
new_df %>%
  group_by(Drug_Regimen) %>%
  shapiro_test(percent_change_Tumor_Volume)
```

The score were normally distributed (p > 0.05) for each group, as assessed by Shapiro-Wilk’s test of normality.

### Create QQ plots for each group level:

QQ plot draws the correlation between a given data and the normal distribution. 

```{r}
ggqqplot(new_df, "percent_change_Tumor_Volume", facet.by = "Drug_Regimen", col="red")
```

### Conclusion:

All the points fall approximately along the reference line, for each cell. So we can assume normality of the data.

### Homogeneity of variance assumption

The residuals versus fits plot can be used to check the homogeneity of variances.

```{r}
plot(model, 1)
```

### Conclusion:

In the plot above, there is no evident relationships between residuals and fitted values (the mean of each group), which is good. So, we can assume the homogeneity of variances.

### Step 1: Setup Null Hypothesis and Alternate Hypothesis

### H0 = mu0 = mu01 = mu02 = mu03 (i.e., There is no difference between the mean percent change in tumor volume for the four drug categories.)

### H1 = Not all means are equal

### Alpha = 0.05


### Computation for ANOVA Test


```{r}
#result_aov <- new_df %>% anova_test(percent_change_Tumor_Volume ~ Drug_Regimen)
result_aov <-anova(lm(percent_change_Tumor_Volume ~ Drug_Regimen, new_df))

result_aov
```

### Another similar Anova test using aov function: 

```{r}
table <- aov(percent_change_Tumor_Volume ~ Drug_Regimen, data=new_df)

summary(table)
```
### Report: 

Degree of freedom: 3, since we have 4 categories, so 4-1 =3 degree of freedom
Sum of Squares: 53104
Mean Sum of Squares: 17701
F-Statistics: 69.737, F(3, 96) = 69.74
p-Value: 2.2e-16, this tells weather we found significance difference or not. The p-value less than alpha=0.05 shows that we found the difference in at least two of the means in the data sample. And that is what we suspected from the boxplot analysis.

### Conclusion:

The F-value in an ANOVA is calculated as: variation between sample means / variation within the samples.
The higher the F-value in an ANOVA, the higher the variation between sample means relative to the variation within the samples.
The higher the F-value, the lower the corresponding p-value.

Since the p-value is below a threshold (α = .05), we can reject the null hypothesis of the ANOVA and conclude that there is a statistically significant difference between group means.

Therefore, we can reject the null hypothesis that there is no difference between the means in the data sample.

But we are not sure about which category mean is different, so we perform Post-hoc tests to determine that.


### Post-hoc test:

A significant one-way ANOVA is generally followed up by Tukey post-hoc tests to perform multiple pairwise comparisons between groups. Key R function: tukey_hsd() [rstatix].


```{r}
TukeyHSD(table)
```

### Report TukeyHSD Results:

when p-adj < p-value, there is a significant difference between the two categories mean.

We are 95% confident that the true mean lies between the lwr and upr bounds of confidence Interval.

The p-Value for Infubinol-Capomulin, Ketapril-Capomulin, Placebo-Capomulin is less than alpha=0.05 that shows there is significant difference between the means of these categories.

The p-Value for Infubinol-Capomulin, Ketapril-Capomulin, Placebo-Capomulin is less than alpha=0.05 that shows there is significant difference between the means of these categories.

Thus, Capomulin more effective in reducing the tumor size than Infubinol, or Ketapril drugs categories. 

The visualization below shows the difference in mean between the two categories in the middle of each bar.

Both end limits on each bar shows the upper and lower limits of confidence intervals.



```{r}
plot(TukeyHSD(table), col= rainbow(4))
```


###=====================================================================================

### correlation between the age, weight and the tumor size growth for each drug category?

```{r}
head(capo_df)
```

### Applying Regression Model for Analyzing Correlation between Age_months, weight_g and Tumor_Volume_mm3

```{r}
#fit regression model
model <- lm(Tumor_Volume_mm3~Weight_g+Age_months, data=capo_df)

#view model summary
summary(model)

#By looking at the coefficients, it seems as though weight is accounting for most of the variance (B = 1.76, p=1.49e-08, p<.05). Age is not a significant predictor of tumor size (B = .053, p = .481).
```

### Residuals:
    Min      1Q  Median      3Q     Max 
-7.2433 -0.7903  0.1667  1.5253  4.8761 

This section displays a summary of the distribution of residuals from the regression model. A residual is the difference between the observed value and the predicted value from the regression model.

The minimum residual was -7.2433, the median residual was 0.1667 and the max residual was 4.8761.

### Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.48591    4.32578   0.112    0.912    
Weight_g     1.76129    0.20298   8.677 1.49e-08 ***
Age_months   0.05303    0.07401   0.716    0.481    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

This section displays the estimated coefficients of the regression model. We can use these coefficients to form the following estimated regression equation:

### Tumor_Volume_mm3 = 0.48591 + 1.76129*Weight_g + 0.05303*Age_months

Estimate: The estimated coefficient. This tells us about the average increase in the response variable associated with a one unit increase in the predictor variable, assuming all other predictor variables are held constant.

Std. Error: This is the standard error of the coefficient. This is a measure of the uncertainty in our estimate of the coefficient.

t value: This is the t-statistic for the predictor variable, calculated as (Estimate) / (Std. Error).

Residual standard error: This tells us the average distance that the observed values fall from the regression line. The smaller the value, the better the regression model can fit the data.

Multiple R-Squared: This is known as the coefficient of determination. It tells us the proportion of the variance in the response variable that can be explained by the predictor variables. This value ranges from 0 to 1. The closer it is to 1, the better the predictor variables are able to predict the value of the response variable.

Adjusted R-squared: This is a modified version of R-squared that has been adjusted for the number of predictors in the model. It is always lower than the R-squared.

F-statistic: This indicates whether the regression model provides a better fit to the data than a model that contains no independent variables. In essence, it tests if the regression model is useful.

p-value: This is the p-value that corresponds to the F-statistic. If this value is less than some significance level (e.g., 0.05), then the regression model fits the data better than a model with no predictors.

When building regression models, we hope that this p-value is less than some significance level because it indicates that the predictor variables are useful for predicting the value of the response variable.

If we used an alpha level of α = .05 to determine which predictors were significant in this regression model, we’d say that weight has (p=1.49e-08) < is (α = .05) and is statistically significant predictors.

while age (p=0.481) > is (α = .05) and is not statistically significant predictors.


### Applying Regression Model for Analyzing Correlation between Tumor_Volume_mm3 and weight seperately.

```{r}
wt_Model <- lm(Tumor_Volume_mm3~Weight_g, data=new_df)
summary(wt_Model)
```

### Conclusion:

If we used an alpha level of α = .05 to determine which predictors were significant in this regression model, we’d say that weight has (p-value: 6e-16) < is (α = .05) and is statistically significant predictors.



### Visualizing the Data:
 
```{r}

ggscatter(new_df, x = "Tumor_Volume_mm3", y = "Weight_g", col="red",
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Tumor Size mm3", ylab = "Weight_g")
```

### Applying Regression Model for Analyzing Correlation between Tumor_Volume_mm3 and Age_months

```{r}
age_Model <- lm(Tumor_Volume_mm3~Age_months, data=new_df)
summary(age_Model)
```

### Conclusion:

If we used an alpha level of α = .05 to determine which predictors were significant in this regression model, we’d say that age has (p-value: 0.936) > is (α = .05) and is not statistically significant predictors.


### Visualizing the Data:
 
```{r}

ggscatter(new_df, x = "Tumor_Volume_mm3", y = "Age_months", col="blue",
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Tumor Size mm3", ylab = "Age")
```
### Explanation of One Way ANOVA Variance Test:

ANOVA (or AOV) is short for ANalysis Of VAriance. While it is commonly used for categorical data, because ANOVA is a type of linear model it can be modified to include continuous data. 

ANOVAs are typically referred to as 1-way and 2-way, which is just a way of saying how many groups are being examined in the model. (ANOVAs can be 3-way or more, but these are less common or end up with different names.) A group is the categorical variable that you are evaluating.

ANOVA test determines the difference in mean between two or more independent groups.

ANOVA checks the impact of one or more group by comparing the means of different samples. We can use ANOVA to prove/disprove if all the medication treatments were equally effective or not. 

ANOVA analyzes the variance in the data to look for differences. It does this by considering two sources of variance, the between-group variance and the within-group variance. 

The between-group variation is calculated by comparing the mean of each group with the overall mean of the data—so individual data points don’t matter quite as much as just comparing group means. 

The within-group variation is the variation of each observation from its group mean. 

For both types of variance, a sums of squares (SS) is the numerical metric used to quantify them and this metric simply sums the distances of each point to the mean. 

The ratio of these SS (between SS divided by within SS) results in an F-statistic, which is the test statistic for ANOVA. 

The F-statistic is then combined with the degrees of freedom (df) to arrive at a p-value, which, we are looking for. 

Another way to think of it is that small p-values come from large F-statistics, and large F-statistics suggest that the between group variance is much larger than the within-group variance.

 So, when the differences in group means is larger and yet the groups are not that variable, we tend to have significant factors in our ANOVAs.

A type 1 error is also known as a false positive and occurs when a researcher incorrectly rejects a true null hypothesis. This means that your report that your findings are significant when in fact they have occurred by chance.

The probability of making a type I error is represented by your alpha level (α), which is the p-value below which you reject the null hypothesis. A p-value of 0.05 indicates that we are willing to accept a 5% chance that we are wrong when we reject the null hypothesis.

We can reduce your risk of committing a type I error by using a lower value for p. For example, a p-value of 0.01 would mean there is a 1% chance of committing a Type I error.

However, using a lower value for alpha means that you will be less likely to detect a true difference if one really exists (thus risking a type II error).


### Conclusion:

Why is this analysis important?

ANOVA test determines the difference in mean between two or more independent groups. 

 It provides the overall test of equality of group means. 

 It can control the overall type I error rate (i.e., false positive finding)

Limitations of the analysis?

One-way ANOVA can only be used when investigating a single factor and a single dependent variable. When comparing the means of three or more groups, it can tell us if at least one pair of means is significantly different, but it can't tell us which pair.

ANOVA assumes that the data is normally distributed. The ANOVA also assumes homogeneity of variance, which means that the variance among the groups should be approximately equal. ANOVA also assumes that the observations are independent of each other.


