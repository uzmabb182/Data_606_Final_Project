---
title: "Data 606 - Final Project"
output:
  html_document: default
  pdf_document: default
---

---
title: "DATA 606 Data Project Proposal"
output: html_document
---



### Libraries Imported

```{r}
library(tidyverse)
library(dplyr)
library(plotly)
library(tidyr)
library(stringr)
library(psych)
library(ggplot2)
```

### Data Preparation

#### load dataset1

```{r }
metadata_df <- read.delim("https://raw.githubusercontent.com/rfpoulos/pymaceuticals/master/data/Mouse_metadata.csv", header=T, sep=",")
head(metadata_df)
```
### Grouping by Drug.Regimen

```{r}
df <- metadata_df %>%
  group_by(Drug.Regimen) 

head(df)
```
### Load dataset2

```{r}
results_df <- read.delim("https://raw.githubusercontent.com/rfpoulos/pymaceuticals/master/data/Study_results.csv", header=T, sep=",")
head(results_df)
```

Introduction: Pymaceuticals Inc., a fictional burgeoning pharmaceutical company based out of San Diego, CA, specializes in drug-based, anti-cancer pharmaceuticals.They have provided the data to test the efficacy of potential drug treatments for squamous cell carcinoma. In this study, 249 mice identified with Squamous cell carcinoma (SCC) tumor growth, kind of skin cancer, were treated through a variety of drug regimens. Over the course of 45 days, tumor development was observed and measured.The objective is to analyze the data to show how four treatments (Capomulin, Infubinol, Ketapril, and Placebo) compare.


### Research question:
### You should phrase your research question in a way that matches up with the scope of inference your dataset allows for.

Question 1: Is Capomulin more or less effective in reducing the tumor size than Infubinol, or Ketapril drugs categories? 

Question 2: Is there a correlation between the age and the tumor size growth for each drug category?

Question 3: Is there a correlation between the weight and the tumor size growth for each drug category?

Hypothesis Test:

Null Hypothesis: There is no difference between the mean percent change in tumor volume for the four drug categories.

Alternate Hypothesis: There is a difference between the mean percent change in tumor volume for the four drug categories.

Approach for answering the research question will be: 

1- Calculate the mean percent change in tumor volume for the four drug categories.

2- Perform the Hypothesis test to find out whether or not the difference exist between the mean tumor size for all four drug categories.

3- Perform linear regression to study the correlation between various variables by calculating the correlation coefficient.

4- Finally analyze the results to find out if Capomulin more or less effective in reducing the tumor size of sample mice than Infubinol, or Ketapril drugs categories.


### Cases:
### What are the cases? How many different drug treatments are there? How many total sample size as well as the sample size by drug treatments are there?

Answer: The metadata_df contain 249 unique mouse id and so are the number of cases that treated with variety of drug regimem .The results_df dataset holds the tumor growth measurments observed for each Mouse ID and carries 1,893 rows results. There are 10 different drug treatments. The total sample size of mouse_id for four treatments (Capomulin, Infubinol, Ketapril, and Placebo) is 100 and the sample size of mouse_id by drug treatments is 25 each.


### Data collection:
### Describe the method of data collection.

Answer: Data is collected by the fictitious pharmaceutical company who was testing the efficacy of potential drug treatments for squamous cell carcinoma.
I import the data into my .Rmd file from github.


### Type of study:
### What type of study is this (observational/experiment)?

Answer: This is an experimental study.A group of 249 mice were monitored after administration of a variety of drug regimens over a 45-day treatment period. The impact of Capomulin on tumor growth, metastasis and survival rates were monitored, along with Infubinol, Ketapril, and Placebo.


### Data Source:
### If you collected the data, state self-collected. If not, provide a citation/link.

Answer: The citation and data collection links are as follows. 

In my search for the experimental datasets, I found the Mouse_metadata and the Study_results on the GitHub link provided below:

https://raw.githubusercontent.com/rfpoulos/pymaceuticals/master/data/Mouse_metadata.csv

https://raw.githubusercontent.com/rfpoulos/pymaceuticals/master/data/Study_results.csv

Upon further research in finding the original source of the the dataset, I found that these datasets are provided by Pymaceuticals Inc., a fictional burgeoning pharmaceutical company based out of San Diego, CA, specializes in drug-based, anti-cancer pharmaceuticals. Below is the link for the original source of the datasets.


https://c-l-nguyen.github.io/web-design-challenge/index.html



### Response
### What is the response variable, and what type is it (numerical/categorical)?

Answer: The response variable is the size of tumor, "Tumor.Volume..mm3." and it holds a numerical data.

### Explanatory

What is the explanatory variable, and what type is it (numerical/categorical)?

Answer: The explanatory variable is the "Drug.Regimen" and it holds a categorical data and "Timepoint" which holds numerical data. The 'Timepoint' unit is 'days'.

### Relevant summary statistics: (Tables and Charts)

Provide summary statistics relevant to your research question. For example, if youâ€™re comparing means across groups provide means, SDs, sample sizes of each group. This step requires the use of R, hence a code chunk is provided below. Insert more code chunks as needed.

```{r}
summary(metadata_df)
```

### Summary Statistic

```{r}
summary(results_df)
```

### Sample Sizes for metadata_df

```{r}
nrow(metadata_df)
```

### Sample Sizes for results_df

```{r}
nrow(results_df)
```

### How many drug treatments are there?

```{r}

drug_count <- unique(metadata_df$Drug.Regimen)

drug_count
```

```{r}

length(drug_count)
```

### Sample sizes of mouse_id by drug treatment

```{r}
capomulin_df <- filter(metadata_df, Drug.Regimen=="Capomulin")

head(capomulin_df)
```

```{r}
nrow(capomulin_df)
```

```{r}
infubinol_df <- filter(metadata_df, Drug.Regimen=="Infubinol")

nrow(infubinol_df)
```

```{r}
ketapril_df <- filter(metadata_df, Drug.Regimen=="Ketapril")

nrow(ketapril_df)
```

```{r}
placebo_df <- filter(metadata_df, Drug.Regimen=="Placebo")

nrow(placebo_df)
```

### Performing full outer join, so that no data is lost

```{r}
merge_df <- merge(x = metadata_df, y = results_df, all = TRUE)

head(merge_df)
```

```{r}
glimpse(merge_df)
```

### Dropping the NA rows

```{r}
merge_df <- merge_df %>% drop_na()

head(merge_df)
```


### Change colnames of some columns
### assigning new names to the columns of the merged data frame
### Colnames(df)[2] <- "new_col2"

```{r}
colnames(merge_df)[1] <- c("Mouse_Id")
colnames(merge_df)[2] <- c("Drug_Regimen")
colnames(merge_df)[5] <- c("Weight_g")
colnames(merge_df)[7] <- c("Tumor_Volume_mm3")
colnames(merge_df)[8] <- c("Metastatic_Sites")

head(merge_df)
```

```{r}
merge_df %>% group_by(Mouse_Id, Timepoint)

head(merge_df)
```


```{r}
df1 <- select(merge_df, Drug_Regimen, Tumor_Volume_mm3, Age_months, Weight_g)
head(df1)
```

```{r}
df1 <- group_by(df1, Drug_Regimen)
head(df1)
```

### Finding the summary statistics of Tumor_Volume

```{r}
stats_df <- df1 %>% summarise(
  Tumor_Volume_mean = mean(Tumor_Volume_mm3), Tumor_Volume_median = median(Tumor_Volume_mm3), Tumor_Volume_sd = sd(Tumor_Volume_mm3), Tumor_Volume_se = sd(Tumor_Volume_mm3)/sqrt(length((Tumor_Volume_mm3))))

head(stats_df)
```

### Comparing means of tumor size by drug treatment.

```{r}
library(ggplot2)

# plot mean salaries
ggplot(stats_df, 
       aes(x = Drug_Regimen, 
           y = Tumor_Volume_mean)) +
  geom_bar(stat = "identity",  fill = "cornflowerblue")
```

### Side-by-side box plots are very useful for comparing groups (i.e., the levels of a categorical variable) on a numerical variable. Outliers are prominent for Drug_Regimen Capomulin, Propriva, Ramicane and Stelasyn.  

```{r}
ggplot(merge_df, 
       aes(x = Drug_Regimen, 
           y = Tumor_Volume_mm3)) +
  geom_boxplot() +
  labs(title = "Mean distribution by Drug_Regimen")

```

### Finding the mice count of each Drug Regimen

```{r}
count_df <- df1 %>% count(Drug_Regimen)

count_df
```

### Ploting the number of mice in each drug regimen

```{r}
barplot(c(230, 178, 178, 188, 186, 181, 161, 228, 181, 182),
        names.arg=c("Capomulin","Ceftamin","Infubinol","Ketapril","Naftisol", "Placebo", "Propriva", "Ramicane", "Stelasyn", "Zoniferol"),
        ylim=c(0,250),
        col=c("beige","orange","lightgreen","lightblue","yellow", "blue", "green", "pink", "purple", "red"),
        ylab="Count of Mice per Drug Regimen")
```


### Remove duplicate rows across entire data frame

```{r}

merge_df <- merge_df[!duplicated(merge_df), ]

head(merge_df)
```

### filter by Capomulin, Infubinol, Ketapril, and Placebo

```{r}

capomulin_df <- filter(merge_df, Drug_Regimen == "Capomulin")
infubinol_df <- filter(merge_df, Drug_Regimen == "Infubinol")
ketapril_df <- filter(merge_df, Drug_Regimen == "Ketapril")
placebo_df <- filter(merge_df, Drug_Regimen == "Placebo")


view(capomulin_df)
```

### To generate a scatter plot of average tumor volume vs. mouse weight for all mice in the Capomulin regimen.
### First we calculate the final tumor volume of each mouse_id across four of the treatment regimens:  
### (Capomulin, Infubinol, Ketapril, and Placebo)

### Since not all mice lived until timepoint 45, we start by getting the last (greatest) timepoint for each mouse

### capomulin_df:

```{r}
capo_df1 <- select(capomulin_df, Mouse_Id, Timepoint, Tumor_Volume_mm3) %>%
  group_by(Mouse_Id) %>%
  filter(Timepoint == max(Timepoint, na.rm=TRUE))

head(capo_df1)
```

### Find the average weight by mice_id in Capomulin_df

```{r}
capo_df2 <- select(capomulin_df, Mouse_Id, Weight_g) %>%
  group_by(Mouse_Id) %>%
 summarise(Average_weight = mean(Weight_g, na.rm=TRUE))

head(capo_df2)
```

### Joining the two df's for adding average weight

```{r}

capo_df <- capo_df1 %>% inner_join(capo_df2, by = "Mouse_Id")

head(capo_df)
```

### Find the average age by mice_id in Capomulin_df

```{r}
capo_df3 <- select(capomulin_df, Mouse_Id, Age_months) %>%
  group_by(Mouse_Id) %>%
 summarise(Average_age = mean(Age_months, na.rm=TRUE))

head(capo_df3)
```

### Joining the two df's for adding average age

```{r}

capo_df <- capo_df %>% inner_join(capo_df3, by = "Mouse_Id")

head(capo_df)
```

### summerize the Tumor_Volume_mm3

```{r}

capo_df$Tumor_Volume_mm3 %>%
  summary()
```

### Standard Deviation

```{r}
capo_df$Tumor_Volume_mm3 %>% sd()
```


### For project proposal, plotting correlation matrices with all the relevant variables for Capomulin drug to analyze. 

### capomulin_df Vs Age_months

```{r}

# Creating the plot
plot(capo_df$Average_age, capo_df$Tumor_Volume_mm3, pch = 19, col = "blue")

# Regression line
abline(lm(capo_df$Tumor_Volume_mm3 ~ capo_df$Average_age), col = "red", lwd = 3)

# Pearson correlation
text(paste("Correlation:", round(cor(capo_df$Average_age, capo_df$Tumor_Volume_mm3), 2)), x = 25, y = 95)
```

### capomulin_df Vs Weight_g

```{r}

# Creating the plot
plot(capo_df$Average_weight, capo_df$Tumor_Volume_mm3, pch = 19, col = "blue")

# Regression line
abline(lm(capo_df$Tumor_Volume_mm3 ~ capo_df$Average_weight), col = "red", lwd = 3)

# Pearson correlation
text(paste("Correlation:", round(cor(capo_df$Average_weight, capo_df$Tumor_Volume_mm3), 2)), x = 25, y = 95)
```

### Correlation Matrix

```{r}
pairs(capo_df[,2:5], pch = 19, col = "blue")
```

### Infubinol_df:


```{r}

infu_df1 <- select(infubinol_df, Mouse_Id, Timepoint, Tumor_Volume_mm3) %>%
  group_by(Mouse_Id) %>%
  filter(Timepoint == max(Timepoint, na.rm=TRUE))

### Find the average weight by mice_id in Infubinol_df


infu_df2 <- select(infubinol_df, Mouse_Id, Weight_g) %>%
  group_by(Mouse_Id) %>%
 summarise(Average_weight = mean(Weight_g, na.rm=TRUE))

### Joining the two df's for adding average weight

infu_df <- infu_df1 %>% inner_join(infu_df2, by = "Mouse_Id")

### Find the average age by mice_id in Capomulin_df

infu_df3 <- select(infubinol_df, Mouse_Id, Age_months) %>%
  group_by(Mouse_Id) %>%
 summarise(Average_age = mean(Age_months, na.rm=TRUE))

### Joining the two df's for adding average age

infu_df <- infu_df %>% inner_join(infu_df3, by = "Mouse_Id")

head(infu_df)
```

### summerize the Tumor_Volume_mm3

```{r}

infu_df$Tumor_Volume_mm3 %>%
  summary()
```

### Standard Deviation

```{r}
infu_df$Tumor_Volume_mm3 %>% sd()
```


### infubinol_df Vs Age_months

```{r}

# Creating the plot
plot(infu_df$Average_age, infu_df$Tumor_Volume_mm3, pch = 19, col = "green")

# Regression line
abline(lm(infu_df$Tumor_Volume_mm3 ~ infu_df$Average_age), col = "red", lwd = 3)

# Pearson correlation
text(paste("Correlation:", round(cor(infu_df$Average_age, infu_df$Tumor_Volume_mm3), 2)), x = 25, y = 95)
```

### infubinol_df Vs Weight_g

```{r}

# Creating the plot
plot(infu_df$Average_weight, infu_df$Tumor_Volume_mm3, pch = 19, col = "green")

# Regression line
abline(lm(infu_df$Tumor_Volume_mm3 ~ infu_df$Average_weight), col = "red", lwd = 3)

# Pearson correlation
text(paste("Correlation:", round(cor(infu_df$Average_weight, infu_df$Tumor_Volume_mm3), 2)), x = 25, y = 95)
```


```{r}
pairs(infu_df[,2:5], pch = 19, col = "green")
```

### ketapril_df:

```{r}
keta_df1 <- select(ketapril_df, Mouse_Id, Timepoint, Tumor_Volume_mm3) %>%
  group_by(Mouse_Id) %>%
  filter(Timepoint == max(Timepoint, na.rm=TRUE))

### Find the average weight by mice_id in Infubinol_df


keta_df2 <- select(ketapril_df, Mouse_Id, Weight_g) %>%
  group_by(Mouse_Id) %>%
 summarise(Average_weight = mean(Weight_g, na.rm=TRUE))

### Joining the two df's for adding average weight

keta_df <- keta_df1 %>% inner_join(keta_df2, by = "Mouse_Id")

### Find the average age by mice_id in Capomulin_df

keta_df3 <- select(ketapril_df, Mouse_Id, Age_months) %>%
  group_by(Mouse_Id) %>%
 summarise(Average_age = mean(Age_months, na.rm=TRUE))

### Joining the two df's for adding average age

keta_df <- keta_df %>% inner_join(keta_df3, by = "Mouse_Id")

head(keta_df)
```

### summerize the Tumor_Volume_mm3

```{r}

keta_df$Tumor_Volume_mm3 %>%
  summary()
```

### Standard Deviation

```{r}

keta_df$Tumor_Volume_mm3 %>% sd()
```

### ketapril_df Vs Age_months

```{r}

# Creating the plot
plot(keta_df$Average_age, keta_df$Tumor_Volume_mm3, pch = 19, col = "purple")

# Regression line
abline(lm(keta_df$Tumor_Volume_mm3 ~ keta_df$Average_age), col = "red", lwd = 3)

# Pearson correlation
text(paste("Correlation:", round(cor(keta_df$Average_age, keta_df$Tumor_Volume_mm3), 2)), x = 25, y = 95)
```

### ketapril_df Vs Weight_g

```{r}

# Creating the plot
plot(keta_df$Average_weight, keta_df$Tumor_Volume_mm3, pch = 19, col = "purple")

# Regression line
abline(lm(keta_df$Tumor_Volume_mm3 ~ keta_df$Average_weight), col = "red", lwd = 3)

# Pearson correlation
text(paste("Correlation:", round(cor(keta_df$Average_weight, keta_df$Tumor_Volume_mm3), 2)), x = 25, y = 95)
```

```{r}
pairs(keta_df[,2:5], pch = 19, col = "purple")
```


### placebo_df:

```{r}
plac_df1 <- select(placebo_df, Mouse_Id, Timepoint, Tumor_Volume_mm3) %>%
  group_by(Mouse_Id) %>%
  filter(Timepoint == max(Timepoint, na.rm=TRUE))

### Find the average weight by mice_id in Infubinol_df


plac_df2 <- select(placebo_df, Mouse_Id, Weight_g) %>%
  group_by(Mouse_Id) %>%
 summarise(Average_weight = mean(Weight_g, na.rm=TRUE))

### Joining the two df's for adding average weight

plac_df <- plac_df1 %>% inner_join(plac_df2, by = "Mouse_Id")

### Find the average age by mice_id in Capomulin_df

plac_df3 <- select(placebo_df, Mouse_Id, Age_months) %>%
  group_by(Mouse_Id) %>%
 summarise(Average_age = mean(Age_months, na.rm=TRUE))

### Joining the two df's for adding average age

plac_df <- plac_df %>% inner_join(plac_df3, by = "Mouse_Id")

head(plac_df)
```

### summerize the Tumor_Volume_mm3

```{r}

plac_df$Tumor_Volume_mm3 %>%
  summary()
```

### Standard Deviation

```{r}

plac_df$Tumor_Volume_mm3 %>% sd()
```


### placebo_df Vs Age_months

```{r}

# Creating the plot
plot(plac_df$Average_age, plac_df$Tumor_Volume_mm3, pch = 19, col = "lightblue")

# Regression line
abline(lm(plac_df$Tumor_Volume_mm3 ~ plac_df$Average_age), col = "red", lwd = 3)

# Pearson correlation
text(paste("Correlation:", round(cor(plac_df$Average_age, plac_df$Tumor_Volume_mm3), 2)), x = 25, y = 95)
```

### placebo_df Vs Weight_g

```{r}

# Creating the plot
plot(plac_df$Average_weight, plac_df$Tumor_Volume_mm3, pch = 19, col = "lightblue")

# Regression line
abline(lm(plac_df$Tumor_Volume_mm3 ~ plac_df$Average_weight), col = "red", lwd = 3)

# Pearson correlation
text(paste("Correlation:", round(cor(plac_df$Average_weight, plac_df$Tumor_Volume_mm3), 2)), x = 25, y = 95)
```

```{r}
pairs(plac_df[,2:5], pch = 19, col = "lightblue")
```

From the plots above, there seems a correlation between weight and Tumor size for capomulin drug regimen but will be checked by calculating the correlation coefficient.


# Answer the Research Question:

## loading the following required packages:

```{r}
library(tidyverse)
library(ggpubr)
library(rstatix)
library(tidyverse)
library(infer)
library(moonBook)
library(webr)
```

### Pearson correlation (r)

which measures a linear dependence between two variables (x and y). Itâ€™s also known as a parametric correlation test because it depends to the distribution of the data. It can be used only when x and y are from normal distribution. The plot of y = f(x) is named the linear regression curve.

cor() computes the correlation coefficient
cor.test() test for association/correlation between paired samples. It returns both the correlation coefficient and the significance level(or p-value) of the correlation .


```{r}
cor(capo_df$Tumor_Volume_mm3, capo_df$Average_weight, method = c("pearson", "kendall", "spearman"))
cor.test(capo_df$Tumor_Volume_mm3, capo_df$Average_weight, method=c("pearson", "kendall", "spearman"))
```

 ### Visualizing the Data:
 
```{r}

ggscatter(capo_df, x = "Tumor_Volume_mm3", y = "Average_weight", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Tumor Size mm3", ylab = "Average Weight")
```
 
R is a measure of any linear trend between two variables. The value of r ranges between âˆ’1 and 1

From the plot above, the value of R=0.88 shows strong linear relationship.

### Calculating R Square for Capomulin drug 

```{r}
lrModel <- lm(Tumor_Volume_mm3~Average_weight, data=capo_df)
summary(lrModel)
```
This shows 76.86% of the variation in the Tumor size can be explained by Average_weight for Capomulin drug 


### Testing the correlation between average age and Tumor size for ketapril drug regimen:

Correlation test is performed to evaluate the association between two or more variables.

keta_df$Average_age, keta_df$Tumor_Volume_mm3
```{r}
cor(keta_df$Tumor_Volume_mm3, keta_df$Average_age, method = c("pearson", "kendall", "spearman"))
cor.test(keta_df$Tumor_Volume_mm3, keta_df$Average_age, method=c("pearson", "kendall", "spearman"))
```

### Visualizing the Data:
 
```{r}

ggscatter(keta_df, x = "Tumor_Volume_mm3", y = "Average_age", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Tumor Size mm3", ylab = "Average Age")
```
R is a measure of any linear trend between two variables. The value of r ranges between âˆ’1 and 1

From the plot above, the value of R=0.28 shows week linear relationship.

### Calculating R Square for ketapril drug 

```{r}
lrModel <- lm(Tumor_Volume_mm3~Average_age, data=keta_df)
summary(lrModel)
```

This shows 07.63% of the variation in the Tumor size can be explained by Average_age for ketapril drug 

### Performing Multiple Linear regression for Capomulin Drug Regemin.

```{r}
#fit regression model
model <- lm(Tumor_Volume_mm3~Average_weight+Average_age, data=capo_df)

#view model summary
summary(model)

```
The coefficient of determination (commonly denoted R2) is the proportion of the variance in the response variable that can be explained by the explanatory variables in a regression model.

The R-squared of the model (shown near the very bottom of the output) turns out to be 0.7739

This means that 77.39% of the variation in the Tumor size can be explained by the weight and the number of age of mice.

### Preparing Data for Capomulin and Placebo Statistical analysis

```{r}

capo_df1 <- select(capomulin_df, Mouse_Id, Drug_Regimen, Timepoint, Tumor_Volume_mm3) %>%
  group_by(Mouse_Id) %>%
  filter(Timepoint == max(Timepoint, na.rm=TRUE))

head(capo_df1)

```

### To select the specific columns capo_df1

```{r}
capo_df1 <- select(capomulin_df, Mouse_Id, Drug_Regimen, Tumor_Volume_mm3)

head(capo_df1)
```

```{r}

plac_df1 <- select(placebo_df, Mouse_Id, Timepoint, Drug_Regimen, Tumor_Volume_mm3) %>%
  group_by(Mouse_Id) %>%
  filter(Timepoint == max(Timepoint, na.rm=TRUE))

head(plac_df1)
```

```{r}
plac_df1 <- select(placebo_df, Mouse_Id, Drug_Regimen, Tumor_Volume_mm3) %>%
  group_by(Mouse_Id)

head(plac_df1)
```

### To select the specific columns plac_df1

```{r}

plac_df1 <- select(placebo_df, Drug_Regimen, Tumor_Volume_mm3)

head(plac_df1)

```

### Joining the two drug regemin datasets

```{r}
df1 <- capo_df1 %>% full_join(plac_df1)

df1 <- select(df1, Drug_Regimen, Tumor_Volume_mm3)
head(df1)
```

### Compute some summary statistics by groups: mean and sd (standard deviation)

```{r}

df1 %>%
  group_by(Drug_Regimen) %>%
  get_summary_stats(Tumor_Volume_mm3, type = "mean_sd")

```

### There is an observed difference, but is this difference statistically significant? In order to answer this question we will conduct a hypothesis test.



# Hypothesis Testing for Capomulin drug regimen:

sample size(n) = 25, sample Tumor size mean(xbar) =  36.67 mm3, standard devation  = 5.71 mm3

### Step 1: Formulate Hypothesis

Null hypothesis: There is no difference between the effectiveness of the four drug regimens. In other words, the difference in mean of the size of Tumor for Capomulin drug regimen result Placebo is zero. 

Null Hypothesis H^0: mu = 54.034
Alternate Hypothesis: mu != 54.034

It is a Two Tailed test.

```{r}
obs_diff <- df1 %>%
  specify(Tumor_Volume_mm3 ~ Drug_Regimen) %>%
  calculate(stat = "diff in means", order = c("Capomulin", "Placebo"))

obs_diff
```

### To simulate the test on the null distribution, which we will save as null

```{r}
null_dist <- df1 %>%
  specify(Tumor_Volume_mm3 ~ Drug_Regimen) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in means", order = c("Capomulin", "Placebo"))

head(null_dist)
```

### visualize this null distribution 

```{r}
ggplot(data = null_dist, aes(x = stat, fill = "color")) +
  geom_histogram()
```


### Before performing a t-test, you have to compare two variances.

### F test to compare two variances:

```{r}
x=var.test(Tumor_Volume_mm3 ~ Drug_Regimen, data = df1)
x
```

```{r}

plot(x)
```


### Step 2: Calculate the t_statistics

Here you translate this test on to t_ distribution by calculating the t_statistics

t_statistic = xbar-mu/s/square root of n


### Two-sample t-test:

The two-sample t-test is also known as the independent t-test. The independent samples t-test comes in two different forms:

the standard Studentâ€™s t-test, which assumes that the variance of the two groups are equal.
the Welchâ€™s t-test, which is less restrictive compared to the original Studentâ€™s test. This is the test where you do not assume that the variance is the same in the two groups, which results in the fractional degrees of freedom.


### Calculations:

R computes the Welch t-test, where you do not assume that the variance is the same in the two groups, which results in the fractional degrees of freedom. 

```{r}
t_result <- t.test(Tumor_Volume_mm3 ~ Drug_Regimen, data = df1)

t_result
```

```{r}
plot(t_result)
```


### In the result above:

t is the t-test statistic value (t = -19.993),
df is the degrees of freedom (df= 290.56),
p-value is the significance level of the t-test (p-value = 2.2e-16).
conf.int is the confidence interval of the means difference at 95% (conf.int = [-14.67285 -12.04283]);
sample estimates is the mean value of the sample (mean =  40.67574, 54.03358).

the t-statistic, t = -19.993, 

### Meaning of translating the hypothesis test on to the t_statistics:

sample mean of Capomulin = 40.67574 is way above the sample mean in group Placebo = 54.034 is equivalent to translating that the t-statistics of -19.993 is way above 0.

Similarly sample mean of Capomulin = 40.67574 is way below the sample mean in group Placebo = 54.034 is equivalent to translating that the t-statistics of -19.993 is way below 0.

### Step 3: Determine the Cutoff values for the t_statistics.

So that we can identify the rejection region for the hypothesis testing.

This is done by first specifying the value of alpha which in the context of hypothesis test aka significance level

Typically the value of alpha=0.05 or 0.01 corresponding to 95% or 99% confidence respectively.


So, our cutoff values for the t-statistic, denoted by t cutoff, are those values in the t distribution, with n- 1 degrees of freedom, that cut off, alpha/2 probability to the right, and alpha/2 probability to the left.

This is a two-tail test with one rejection region on the right, and one rejection region on the left.

Hence, the total rejection probability of alpha gets equally divided across the two rejection regions.

### Step 4: Check whether t_statistics falls in the rejection region

### Interpretation:

Hypothesis testing ultimately uses a p-value to weigh the strength of the evidence. The p-value ranges between 0 and 1. It can be interpreted in the following way:

A small p-value (typically â‰¤ 0.05) indicates strong evidence against the null hypothesis, so you reject it.
A large p-value (> 0.05) indicates weak evidence against the null hypothesis, so you fail to reject it.

The p-value of the test is 2.2e-16, which is less than the significance level alpha = 0.05. We can conclude that camopulin average tumor size is significantly different from placebo average tumor size with a p-value = 2.2e-16.

A small p-value (typically â‰¤ 0.05) indicates strong evidence against the null hypothesis,
so we reject the null hypothsisis and accept the alternate hypothesis.

### =============================================================

### Now Preparing Data for ketapril and Placebo Statistical analysis

```{r}

keta_df1 <- select(ketapril_df, Mouse_Id, Drug_Regimen, Timepoint, Tumor_Volume_mm3) %>%
  group_by(Mouse_Id) %>%
  filter(Timepoint == max(Timepoint, na.rm=TRUE))

head(keta_df1)

```

### To select the specific columns keta_df1

```{r}
keta_df1 <- select(ketapril_df, Mouse_Id, Drug_Regimen, Tumor_Volume_mm3)

head(keta_df1)
```

```{r}

keta_df1 <- select(ketapril_df, Mouse_Id, Timepoint, Drug_Regimen, Tumor_Volume_mm3) %>%
  group_by(Mouse_Id) %>%
  filter(Timepoint == max(Timepoint, na.rm=TRUE))

head(keta_df1)
```

```{r}
plac_df1 <- select(placebo_df, Mouse_Id, Drug_Regimen, Tumor_Volume_mm3) %>%
  group_by(Mouse_Id)

head(plac_df1)
```

### To select the specific columns plac_df1

```{r}

plac_df1 <- select(placebo_df, Drug_Regimen, Tumor_Volume_mm3)

head(plac_df1)

```

### Joining the two drug regemin datasets

```{r}
df2 <- keta_df1 %>% full_join(plac_df1)

df2 <- select(df2, Drug_Regimen, Tumor_Volume_mm3)
head(df2)
```

### Compute some summary statistics by groups: mean and sd (standard deviation)

```{r}

df2 %>%
  group_by(Drug_Regimen) %>%
  get_summary_stats(Tumor_Volume_mm3, type = "mean_sd")

```

### There is an observed difference, but is this difference statistically significant? In order to answer this question we will conduct a hypothesis test.



# Hypothesis Testing for Ketapril drug regimen:

sample size(n) = 25, sample Tumor size mean(xbar) =  36.67 mm3, standard devation  = 5.71 mm3

### Step 1: Formulate Hypothesis

Null hypothesis: There is no difference between the effectiveness of the four drug regimens. In other words, the difference in mean of the size of Tumor for Ketapril drug regimen result Placebo is zero. 

Null Hypothesis H^0: mu = 54.034
Alternate Hypothesis: mu != 54.034

It is a Two Tailed test.

```{r}
obs_diff <- df2 %>%
  specify(Tumor_Volume_mm3 ~ Drug_Regimen) %>%
  calculate(stat = "diff in means", order = c("Ketapril", "Placebo"))

obs_diff
```

### To simulate the test on the null distribution, which we will save as null

```{r}
null_dist <- df2 %>%
  specify(Tumor_Volume_mm3 ~ Drug_Regimen) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in means", order = c("Ketapril", "Placebo"))

head(null_dist)
```

### visualize this null distribution 

```{r}
ggplot(data = null_dist, aes(x = stat, fill = "color")) +
  geom_histogram()
```


### Before performing a t-test, you have to compare two variances.

### F test to compare two variances:

```{r}
x=var.test(Tumor_Volume_mm3 ~ Drug_Regimen, data = df2)
x
```

```{r}

plot(x)
```


### Step 2: Calculate the t_statistics

Here you translate this test on to t_ distribution by calculating the t_statistics

t_statistic = xbar-mu/s/square root of n


### Two-sample t-test:

The two-sample t-test is also known as the independent t-test. The independent samples t-test comes in two different forms:

the standard Studentâ€™s t-test, which assumes that the variance of the two groups are equal.
the Welchâ€™s t-test, which is less restrictive compared to the original Studentâ€™s test. This is the test where you do not assume that the variance is the same in the two groups, which results in the fractional degrees of freedom.


### Calculations:

R computes the Welch t-test, where you do not assume that the variance is the same in the two groups, which results in the fractional degrees of freedom. 

```{r}
t_result <- t.test(Tumor_Volume_mm3 ~ Drug_Regimen, data = df2)

t_result
```

```{r}
plot(t_result)
```


### In the result above:

t is the t-test statistic value (t = 4.2331),
df is the degrees of freedom (df = 28.247),
p-value is the significance level of the t-test (p-value = 0.000221).
conf.int is the confidence interval of the means difference at 95% (conf.int = [ 4.529186 13.016035]);
sample estimates is the mean value of the sample (mean =   62.80619, 54.03358).

the t-statistic, t = 4.2331, 

### Meaning of translating the hypothesis test on to the t_statistics:

sample mean of Ketapril = 62.80619 is way above the sample mean in group Placebo = 54.034 is equivalent to translating that the t-statistics of 4.2331 is way above 0.

Similarly sample mean of Ketapril = 62.80619 is way below the sample mean in group Placebo = 54.034 is equivalent to translating that the t-statistics of  4.2331  is way below 0.

### Step 3: Determine the Cutoff values for the t_statistics.

So that we can identify the rejection region for the hypothesis testing.

This is done by first specifying the value of alpha which in the context of hypothesis test aka significance level

Typically the value of alpha=0.05 or 0.01 corresponding to 95% or 99% confidence respectively.


So, our cutoff values for the t-statistic, denoted by t cutoff, are those values in the t distribution, with n- 1 degrees of freedom, that cut off, alpha/2 probability to the right, and alpha/2 probability to the left.

This is a two-tail test with one rejection region on the right, and one rejection region on the left.

Hence, the total rejection probability of alpha gets equally divided across the two rejection regions.

### Step 4: Check whether t_statistics falls in the rejection region

### Interpretation:

Hypothesis testing ultimately uses a p-value to weigh the strength of the evidence. The p-value ranges between 0 and 1. It can be interpreted in the following way:

A small p-value (typically â‰¤ 0.05) indicates strong evidence against the null hypothesis, so you reject it.
A large p-value (> 0.05) indicates weak evidence against the null hypothesis, so you fail to reject it.

The p-value of the test is 0.000221, which is less than the significance level alpha = 0.05. We can conclude that Ketapril average tumor size is significantly different from placebo average tumor size with a p-value = 0.000221.

A small p-value (typically â‰¤ 0.05) indicates strong evidence against the null hypothesis,
so we reject the null hypothsisis and accept the alternate hypothesis.

### =============================================================

### Now Preparing Data for Infubinol and Placebo Statistical analysis

```{r}

infu_df1 <- select(infubinol_df, Mouse_Id, Drug_Regimen, Timepoint, Tumor_Volume_mm3) %>%
  group_by(Mouse_Id) %>%
  filter(Timepoint == max(Timepoint, na.rm=TRUE))

head(infu_df1)

```

### To select the specific columns infu_df1

```{r}
infu_df1 <- select(infubinol_df, Mouse_Id, Drug_Regimen, Tumor_Volume_mm3)

head(infu_df1)
```

```{r}

infu_df1 <- select(infubinol_df, Mouse_Id, Timepoint, Drug_Regimen, Tumor_Volume_mm3) %>%
  group_by(Mouse_Id) %>%
  filter(Timepoint == max(Timepoint, na.rm=TRUE))

head(infu_df1)
```

```{r}
plac_df1 <- select(placebo_df, Mouse_Id, Drug_Regimen, Tumor_Volume_mm3) %>%
  group_by(Mouse_Id)

head(plac_df1)
```

### To select the specific columns plac_df1

```{r}

plac_df1 <- select(placebo_df, Drug_Regimen, Tumor_Volume_mm3)

head(plac_df1)

```

### Joining the two drug regemin datasets

```{r}
df3 <- infu_df1 %>% full_join(plac_df1)

df3 <- select(df3, Drug_Regimen, Tumor_Volume_mm3)
head(df3)
```

### Compute some summary statistics by groups: mean and sd (standard deviation)

```{r}

df3 %>%
  group_by(Drug_Regimen) %>%
  get_summary_stats(Tumor_Volume_mm3, type = "mean_sd")

```

### There is an observed difference, but is this difference statistically significant? In order to answer this question we will conduct a hypothesis test.



# Hypothesis Testing for Infubinol drug regimen:

sample size(n) = 25, sample Tumor size mean(xbar) =  36.67 mm3, standard devation  = 5.71 mm3

### Step 1: Formulate Hypothesis

Null hypothesis: There is no difference between the effectiveness of the four drug regimens. In other words, the difference in mean of the size of Tumor for Infubinol drug regimen result Placebo is zero. 

Null Hypothesis H^0: mu = 54.034
Alternate Hypothesis: mu != 54.034

It is a Two Tailed test.

```{r}
obs_diff <- df3 %>%
  specify(Tumor_Volume_mm3 ~ Drug_Regimen) %>%
  calculate(stat = "diff in means", order = c("Infubinol", "Placebo"))

obs_diff
```

### To simulate the test on the null distribution, which we will save as null

```{r}
null_dist <- df3 %>%
  specify(Tumor_Volume_mm3 ~ Drug_Regimen) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in means", order = c("Infubinol", "Placebo"))

head(null_dist)
```

### visualize this null distribution 

```{r}
ggplot(data = null_dist, aes(x = stat, fill = "color")) +
  geom_histogram()
```


### Before performing a t-test, you have to compare two variances.

### F test to compare two variances:

```{r}
x=var.test(Tumor_Volume_mm3 ~ Drug_Regimen, data = df3)
x
```

```{r}

plot(x)
```


### Step 2: Calculate the t_statistics

Here you translate this test on to t_ distribution by calculating the t_statistics

t_statistic = xbar-mu/s/square root of n


### Two-sample t-test:

The two-sample t-test is also known as the independent t-test. The independent samples t-test comes in two different forms:

the standard Studentâ€™s t-test, which assumes that the variance of the two groups are equal.
the Welchâ€™s t-test, which is less restrictive compared to the original Studentâ€™s test. This is the test where you do not assume that the variance is the same in the two groups, which results in the fractional degrees of freedom.


### Calculations:

R computes the Welch t-test, where you do not assume that the variance is the same in the two groups, which results in the fractional degrees of freedom. 

```{r}
t_result <- t.test(Tumor_Volume_mm3 ~ Drug_Regimen, data = df3)

t_result
```

```{r}
plot(t_result)
```


### In the result above:

t is the t-test statistic value (t = 2.2821),
df is the degrees of freedom (df = 28.247),
p-value is the significance level of the t-test (p-value = 0.02981).
conf.int is the confidence interval of the means difference at 95% (conf.int = [0.4342457  7.8550843]);
sample estimates is the mean value of the sample (mean =58.17825   54.03358).

the t-statistic, t = 2.2821, 

### Meaning of translating the hypothesis test on to the t_statistics:

sample mean of Infubinol = 58.17825 is way above the sample mean in group Placebo = 54.034 is equivalent to translating that the t-statistics of 2.2821 is way above 0.

Similarly sample mean of Infubinol = 58.17825 is way below the sample mean in group Placebo = 54.034 is equivalent to translating that the t-statistics of  2.2821  is way below 0.

### Step 3: Determine the Cutoff values for the t_statistics.

So that we can identify the rejection region for the hypothesis testing.

This is done by first specifying the value of alpha which in the context of hypothesis test aka significance level

Typically the value of alpha=0.05 or 0.01 corresponding to 95% or 99% confidence respectively.


So, our cutoff values for the t-statistic, denoted by t cutoff, are those values in the t distribution, with n- 1 degrees of freedom, that cut off, alpha/2 probability to the right, and alpha/2 probability to the left.

This is a two-tail test with one rejection region on the right, and one rejection region on the left.

Hence, the total rejection probability of alpha gets equally divided across the two rejection regions.

### Step 4: Check whether t_statistics falls in the rejection region

### Interpretation:

Hypothesis testing ultimately uses a p-value to weigh the strength of the evidence. The p-value ranges between 0 and 1. It can be interpreted in the following way:

A small p-value (typically â‰¤ 0.05) indicates strong evidence against the null hypothesis, so you reject it.
A large p-value (> 0.05) indicates weak evidence against the null hypothesis, so you fail to reject it.

The p-value of the test is 0.02981, which is less than the significance level alpha = 0.05. We can conclude that Ketapril average tumor size is significantly different from placebo average tumor size with a p-value = 0.02981

A small p-value (typically â‰¤ 0.05) indicates strong evidence against the null hypothesis,
so we reject the null hypothsisis and accept the alternate hypothesis.

